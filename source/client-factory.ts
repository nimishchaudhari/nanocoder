import {appConfig} from './config/index.js';
import {loadPreferences} from './config/preferences.js';
import type {LLMClient, ProviderType} from './types/index.js';
import {existsSync} from 'fs';
import {join} from 'path';
import {createLangChainLLMClient} from './langchain-factory.js';

export async function createLLMClient(
  provider?: ProviderType,
): Promise<{client: LLMClient; actualProvider: ProviderType}> {
	// Check if agents.config.json exists
	const agentsJsonPath = join(process.cwd(), 'agents.config.json');
	const hasConfigFile = existsSync(agentsJsonPath);
	
	// If no provider specified, check user preferences (but only if config exists)
	if (!provider) {
		if (hasConfigFile) {
			const preferences = loadPreferences();
			provider = preferences.lastProvider || 'openai-compatible';
		} else {
			// No config file - force OpenAI-compatible only
			provider = 'openai-compatible';
		}
	}
	
	// If no config file exists but user requested non-supported provider, force OpenAI-compatible
	if (!hasConfigFile && provider !== 'openai-compatible' && provider !== 'openrouter') {
		provider = 'openai-compatible';
	}
	
	// Define available providers based on config file presence
	const allProviders: ProviderType[] = hasConfigFile 
		? ['openai-compatible', 'openrouter']
		: ['openai-compatible'];
	
	// Put the requested provider first, then try others (if config exists)
	const tryOrder = hasConfigFile 
		? [provider, ...allProviders.filter(p => p !== provider)]
		: ['openai-compatible'];
	
	const errors: string[] = [];

	// Try each provider in order
	for (const currentProvider of tryOrder as ProviderType[]) {
		try {
			// Only try OpenAI-compatible and OpenRouter providers
			if (currentProvider === 'openai-compatible' || currentProvider === 'openrouter') {
				// Pass configuration from appConfig to the LangChain factory
				let config;
				if (currentProvider === 'openai-compatible') {
					if (!appConfig.openAICompatible?.baseUrl) {
						throw new Error('OpenAI-compatible API requires baseUrl in config');
					}
					config = {
						baseUrl: appConfig.openAICompatible.baseUrl,
						apiKey: appConfig.openAICompatible.apiKey,
						models: appConfig.openAICompatible.models,
						model: appConfig.openAICompatible.models?.[0],
					};
				} else {
					// OpenRouter
					if (!appConfig.openRouter?.apiKey) {
						throw new Error('OpenRouter requires API key in config');
					}
					if (!appConfig.openRouter?.models || appConfig.openRouter.models.length === 0) {
						throw new Error('OpenRouter requires models array in config');
					}
					config = {
						baseUrl: "https://openrouter.ai/api/v1",
						apiKey: appConfig.openRouter.apiKey,
						models: appConfig.openRouter.models,
						model: appConfig.openRouter.models?.[0],
					};
				}
				
				const result = await createLangChainLLMClient(currentProvider, config);
				return result;
			}
		} catch (error: any) {
			const errorMsg = `${currentProvider}: ${error.message}`;
			errors.push(errorMsg);
		}
	}

  // If we get here, all providers failed
  let combinedError: string;
  
  if (!hasConfigFile) {
    // No config file - only tried OpenAI-compatible
    combinedError = `OpenAI-compatible API unavailable: ${errors[0]?.split(': ')[1] || 'Unknown error'}\n\n` +
      `Please ensure your OpenAI-compatible API is running and configured properly.`;
  } else {
    // Config file exists - tried multiple providers
    combinedError = `All configured providers failed:\n${errors.map(e => `â€¢ ${e}`).join('\n')}\n\n` +
      `Please check your provider configuration in agents.config.json`;
  }
  
  throw new Error(combinedError);
}

